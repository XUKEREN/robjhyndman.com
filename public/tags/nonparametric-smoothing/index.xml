<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nonparametric Smoothing on Rob J Hyndman</title>
    <link>https://robjhyndman.com/tags/nonparametric-smoothing/</link>
    <description>Recent content in Nonparametric Smoothing on Rob J Hyndman</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 05 Oct 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://robjhyndman.com/tags/nonparametric-smoothing/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Two-dimensional smoothing of mortality surfaces with cohort and period ridges</title>
      <link>https://robjhyndman.com/publications/mortality-smoothing/</link>
      <pubDate>Thu, 05 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/mortality-smoothing/</guid>
      <description>BACKGROUND
Mortality rates typically move smoothly over age and time. Exceptions occur, due to events such as wars and epidemics, which create, among other features, ridges in the mortality surface in a particular calendar year or for cohorts born in a particular year.
OBJECTIVES
We aim to develop and evaluate new methods that better model the smooth underlying age-period mortality surface and any cohort or period ridges.
METHODS
We propose two new practical methods for modelling the age-period surface of the logarithms of mortality rates.</description>
    </item>
    
    <item>
      <title>Long-term forecasts of age-specific participation rates with functional data models</title>
      <link>https://robjhyndman.com/publications/participation-rates/</link>
      <pubDate>Sun, 24 Jan 2016 06:33:23 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/participation-rates/</guid>
      <description>Many countries have implemented social programs providing long-term financial or in-kind entitlements. These programs often focus on specific age-groups and consequently their expenditure streams are subject to demographic change. Given the strains already existing on public budgets, long-term forecasts are an increasingly important instrument to monitor the budgetary consequences of social programs. The expected development of the labour force is a key input to these forecasts. We suggest combining a functional data approach to age-profiles of labour market participation rates with information on education, marital status and other exogenous variables to improve long-term forecasts of labour supply.</description>
    </item>
    
    <item>
      <title>MEFM: An R package for long-term probabilistic forecasting of electricity demand</title>
      <link>https://robjhyndman.com/seminars/isf2015/</link>
      <pubDate>Mon, 22 Jun 2015 23:00:41 +0000</pubDate>
      
      <guid>https://robjhyndman.com/seminars/isf2015/</guid>
      <description>International Symposium on Forecasting Riverside, California
I will describe and demonstrate a new open-source R package that implements the Monash Electricity Forecasting Model, a semi-parametric probabilistic approach to forecasting long-term electricity demand. The underlying model proposed in Hyndman and Fan (2010) is now widely used in practice, particularly in Australia. The model has undergone many improvements and developments since it was first proposed, and these have been incorporated in this R implementation.</description>
    </item>
    
    <item>
      <title>Probabilistic forecasting of peak electricity demand</title>
      <link>https://robjhyndman.com/seminars/sce2015/</link>
      <pubDate>Thu, 18 Jun 2015 23:00:41 +0000</pubDate>
      
      <guid>https://robjhyndman.com/seminars/sce2015/</guid>
      <description>Southern California Edison Rosemead, California
Electricity demand forecasting plays an important role in short-term load allocation and long-term planning for future generation facilities and transmission augmentation. It is a challenging problem because of the different uncertainties including underlying population growth, changing technology, economic conditions, prevailing weather conditions (and the timing of those conditions), as well as the general randomness inherent in individual usage. It is also subject to some known calendar effects due to the time of day, day of week, time of year, and public holidays.</description>
    </item>
    
    <item>
      <title>STR: A Seasonal-Trend Decomposition Procedure Based on Regression</title>
      <link>https://robjhyndman.com/publications/str/</link>
      <pubDate>Sun, 07 Jun 2015 22:50:17 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/str/</guid>
      <description>We propose new generic methods for decomposing seasonal data: STR (a Seasonal-Trend decomposition procedure based on Regression) and Robust STR. In some ways, STR is similar to Ridge Regression and Robust STR can be related to LASSO. Our new methods are much more general than any alternative time series decomposition methods. They allow for multiple seasonal and cyclic components, and multiple linear regressors with constant, flexible, seasonal and cyclic influence. Seasonal patterns (for both seasonal components and seasonal regressors) can be fractional and flexible over time; moreover they can be either strictly periodic or have a more complex topology.</description>
    </item>
    
    <item>
      <title>Low-dimensional decomposition, smoothing and forecasting of sparse functional data</title>
      <link>https://robjhyndman.com/publications/ropes/</link>
      <pubDate>Thu, 05 Jun 2014 03:53:48 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/ropes/</guid>
      <description>We propose a new generic method ROPES (Regularized Optimization for Prediction and Estimation with Sparse data) for decomposing, smoothing and forecasting two-dimensional sparse data. In some ways, ROPES is similar to Ridge Regression, the LASSO, Principal Component Analysis (PCA) and Maximum-Margin Matrix Factorisation (MMMF). Using this new approach, we propose a practical method of forecasting mortality rates, as well as a new method for interpolating and extrapolating sparse longitudinal data. We also show how to calculate prediction intervals for the resulting estimates.</description>
    </item>
    
    <item>
      <title>Nonparametric and semiparametric response surface methodology: a review of designs, models and optimization techniques</title>
      <link>https://robjhyndman.com/publications/rsm-review/</link>
      <pubDate>Thu, 31 Oct 2013 12:27:07 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/rsm-review/</guid>
      <description>Abstract: Since the introduction of Response Surface Methodology in the 1950s, there have been many developments with the aim of expanding the range of applications of the methodology. Various new design, modeling and optimization techniques have been introduced for coping with unknown input-output relationships, costly or time-consuming experimental studies and irregular experimental regions (e.g., non-cubic or non-spherical regions induced by constraints in the input variables). Such developments may involve many different research areas simultaneously (e.</description>
    </item>
    
    <item>
      <title>Short-term load forecasting based on a semi-parametric additive model</title>
      <link>https://robjhyndman.com/publications/stlf/</link>
      <pubDate>Wed, 01 Feb 2012 06:37:48 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/stlf/</guid>
      <description>Short-term load forecasting is an essential instrument in power system planning, operation and control. Many operating decisions are based on load forecasts, such as dispatch scheduling of generating capacity, reliability analysis, and maintenance planning for the generators. Overestimation of electricity demand will cause a conservative operation, which leads to the start-up of too many units or excessive energy purchase, thereby supplying an unnecessary level of reserve. On the contrary, underestimation may result in a risky operation, with insufficient preparation of spinning reserve, causing the system to operate in a vulnerable region to the disturbance.</description>
    </item>
    
    <item>
      <title>Forecasting electricity demand distributions using a semiparametric additive model </title>
      <link>https://robjhyndman.com/seminars/electricity-forecasting/</link>
      <pubDate>Mon, 03 Oct 2011 03:11:47 +0000</pubDate>
      
      <guid>https://robjhyndman.com/seminars/electricity-forecasting/</guid>
      <description>Talk given at
 University of Melbourne, 11 October 2011. University of Adelaide, 16 March 2012 Monash University, 16 May 2012 La Trobe University, 24 May 2012 EDF, Paris. 4 September 2012 University of New South Wales, 1 November 2012  Abstract: Electricity demand forecasting plays an important role in short-term load allocation and long-term planning for future generation facilities and transmission augmentation. Planners must adopt a probabilistic view of potential peak demand levels, therefore density forecasts (providing estimates of the full probability distributions of the possible future values of the demand) are more helpful than point forecasts, and are necessary for utilities to evaluate and hedge the financial risk accrued by demand variability and forecasting uncertainty.</description>
    </item>
    
    <item>
      <title>Short-term load forecasting based on a semi-parametric additive model</title>
      <link>https://robjhyndman.com/publications/aupec2010/</link>
      <pubDate>Wed, 21 Jul 2010 09:15:13 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/aupec2010/</guid>
      <description>Short-term load forecasting is an essential instrument in power system planning, operation and control. Many operating decisions are based on load forecasts, such as dispatch scheduling of generating capacity, reliability analysis, and maintenance planning for the generators. Overestimation of electricity demand will cause a conservative operation, which leads to the start-up of too many units or excessive energy purchase, thereby supplying an unnecessary level of reserve. On the contrary, underestimation may result in a risky operation, with insufficient preparation of spinning reserve, causing the system to operate in a vulnerable region to the disturbance.</description>
    </item>
    
    <item>
      <title>Functionalization of microarray devices: process optimization using a multiobjective PSO and multiresponse MARS modeling</title>
      <link>https://robjhyndman.com/publications/microarray-optimization/</link>
      <pubDate>Sun, 07 Feb 2010 23:12:26 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/microarray-optimization/</guid>
      <description>An evolutionary approach for the optimization of microarray coatings produced via sol-gel chemistry is presented. The aim of the methodology is to face the challenging aspects of the problem: high dimensional variable space, constraints on the independent variables, multiple responses, expensive or time-consuming experimental trials, expected complexity of the functional relationships between independent and response variables. The proposed approach iteratively select a set of experiments by combining a multiobjective Particle Swarm Optimization (PSO) and a multiresponse Multivariate Adaptive Regression Spines (MARS) model.</description>
    </item>
    
    <item>
      <title>Density forecasting for long-term peak electricity demand</title>
      <link>https://robjhyndman.com/publications/peak-electricity-demand/</link>
      <pubDate>Sat, 02 Jan 2010 23:10:12 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/peak-electricity-demand/</guid>
      <description>Abstract: Long-term electricity demand forecasting plays an important role in planning for future generation facilities and transmission augmentation. In a long term context, planners must adopt a probabilistic view of potential peak demand levels, therefore density forecasts (providing estimates of the full probability distributions of the possible future values of the demand) are more helpful than point forecasts, and are necessary for utilities to evaluate and hedge the financial risk accrued by demand variability and forecasting uncertainty.</description>
    </item>
    
    <item>
      <title>Nonparametric time series forecasting with dynamic updating</title>
      <link>https://robjhyndman.com/publications/dynamic-updating1/</link>
      <pubDate>Sun, 12 Jul 2009 23:46:32 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/dynamic-updating1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Projection pursuit estimator for multivariate conditional densities</title>
      <link>https://robjhyndman.com/publications/projection-pursuit-estimator-for-multivariate-conditional-densities/</link>
      <pubDate>Sun, 17 Sep 2006 02:42:27 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/projection-pursuit-estimator-for-multivariate-conditional-densities/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Bayesian approach to bandwidth selection for multivariate kernel density estimation</title>
      <link>https://robjhyndman.com/publications/bandwidth-selection-for-multivariate-kernel-density-estimation-using-mcmc/</link>
      <pubDate>Thu, 20 Jul 2006 06:19:21 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/bandwidth-selection-for-multivariate-kernel-density-estimation-using-mcmc/</guid>
      <description>Kernel density estimation for multivariate data is an important technique that has a wide range of applications. However, it has received significantly less attention than its univariate counterpart. The lower level of interest in multivariate kernel density estimation is mainly due to the increased difficulty in deriving an optimal data-driven bandwidth as the dimension of the data increases. We provide Markov chain Monte Carlo (MCMC) algorithms for estimating optimal bandwidth matrices for multivariate kernel density estimation.</description>
    </item>
    
    <item>
      <title>Local linear multivariate regression with variable bandwidth in the presence of heteroscedasticity</title>
      <link>https://robjhyndman.com/publications/local-linear-multivariate-regression-with-variable-bandwidth-in-the-presence-of-heteroscedasticity/</link>
      <pubDate>Mon, 01 May 2006 01:50:39 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/local-linear-multivariate-regression-with-variable-bandwidth-in-the-presence-of-heteroscedasticity/</guid>
      <description>We present a local linear estimator with variable bandwidth for multivariate nonparametric regression. We prove its consistency and asymptotic normality in the interior of the observed data and obtain its rates of convergence. This result is used to obtain practical direct plug-in bandwidth selectors for heteroscedastic regression in one and two dimensions. We show that the local linear estimator with variable bandwidth has better goodness-of-fit properties than the local linear estimator with constant bandwidth, in the presence of heteroscedasticity.</description>
    </item>
    
    <item>
      <title>Local linear forecasts using cubic smoothing splines</title>
      <link>https://robjhyndman.com/publications/splinefcast/</link>
      <pubDate>Sun, 16 Jan 2005 03:52:09 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/splinefcast/</guid>
      <description>We show how cubic smoothing splines fitted to univariate time series data can be used to obtain local linear forecasts. Our approach is based on a stochastic state space model which allows the use of a likelihood approach for estimating the smoothing parameter, and which enables easy construction of prediction intervals. We show that our model is a special case of an ARIMA(0,2,2) model and we provide a simple upper bound for the smoothing parameter to ensure an invertible model.</description>
    </item>
    
    <item>
      <title>Nonparametric confidence intervals for receiver operating characteristic curves</title>
      <link>https://robjhyndman.com/publications/nonparametric-confidence-intervals-for-receiver-operating-characteristic-curves/</link>
      <pubDate>Fri, 16 Jul 2004 03:34:10 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/nonparametric-confidence-intervals-for-receiver-operating-characteristic-curves/</guid>
      <description>We study methods for constructing confidence intervals, and confidence bands, for estimators of receiver operating characteristics. Particular emphasis is placed on the way in which smoothing should be implemented, when estimating either the characteristic itself or its variance. We show that substantial undersmoothing is necessary if coverage properties are not to be impaired. A theoretical analysis of the problem suggests an empirical, plug-in rule for bandwidth choice, optimising the coverage accuracy of interval estimators.</description>
    </item>
    
    <item>
      <title>Spline interpolation for demographic variables: the monotonicity problem</title>
      <link>https://robjhyndman.com/publications/monotonic-splines-2/</link>
      <pubDate>Fri, 16 Jan 2004 03:40:50 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/monotonic-splines-2/</guid>
      <description>In demography, it is often necessary to obtain a monotonic interpolation of data. A solution to this problem is available using the Hyman filter for cubic splines. However, this does not seem to be well-known amongst demographers, and no implementation of the procedure is readily available. We remedy these problems by outlining the relevant ideas here, and providing a function for the R package.
R code</description>
    </item>
    
    <item>
      <title>Improved methods for bandwidth selection when estimating ROC curves</title>
      <link>https://robjhyndman.com/publications/improved-methods-for-bandwidth-selection-when-estimating-roc-curves/</link>
      <pubDate>Sun, 16 Feb 2003 03:28:09 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/improved-methods-for-bandwidth-selection-when-estimating-roc-curves/</guid>
      <description>The receiver operating characteristic (ROC) curve is used to describe the performance of a diagnostic test which classifies observations into two groups. We introduce new methods for selecting bandwidths when computing kernel estimates of ROC curves. Our techniques allow for interaction between the distributions of each group of observations and gives substantial improvement in MISE over other proposed methods, especially when the two distributions are very different.
Keywords: bandwidth selection; binary classification; kernel estimator; ROC curve.</description>
    </item>
    
    <item>
      <title>Mixed model-based hazard estimation</title>
      <link>https://robjhyndman.com/publications/mixed-model-based-hazard-estimation/</link>
      <pubDate>Sat, 16 Nov 2002 03:18:37 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/mixed-model-based-hazard-estimation/</guid>
      <description>We propose a new method for estimation of the hazard function from a set of censored failure time data, with a view to extending the general approach to more complicated models. The approach is based on a mixed model representation of penalized spline hazard estimators. One payoff is the automation of the smoothing parameter choice through restricted maximum likelihood. Another is the option to use standard mixed model software for automatic hazard estimation.</description>
    </item>
    
    <item>
      <title>Nonparametric estimation and symmetry tests for conditional density functions</title>
      <link>https://robjhyndman.com/publications/nonparametric-estimation-and-symmetry-tests-for-conditional-density-functions/</link>
      <pubDate>Tue, 16 Jul 2002 03:23:33 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/nonparametric-estimation-and-symmetry-tests-for-conditional-density-functions/</guid>
      <description>We suggest two new methods for conditional density estimation. The first is based on locally fitting a log-linear model, and is in the spirit of recent work on locally parametric techniques in density estimation. The second method is a constrained local polynomial estimator. Both methods always produce non-negative estimators. We propose an algorithm suitable for selecting the two bandwidths for either estimator. We also develop a new bootstrap test for the symmetry of conditional density functions.</description>
    </item>
    
    <item>
      <title>Bandwidth selection for kernel conditional density estimation</title>
      <link>https://robjhyndman.com/publications/bandwidth-selection-for-kernel-conditional-density-estimation/</link>
      <pubDate>Sat, 16 Jun 2001 03:08:35 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/bandwidth-selection-for-kernel-conditional-density-estimation/</guid>
      <description>We consider bandwidth selection for the kernel estimator of conditional density with one explanatory variable. Several bandwidth selection methods are derived ranging from fast rules-of-thumb which assume the underlying densities are known to relatively slow procedures which use the bootstrap. The methods are compared and a practical bandwidth selection strategy which combines the methods is proposed. The methods are compared using two simulation studies and a real data set.
Keywords: density estimation; kernel smoothing; conditioning; bandwidth selection.</description>
    </item>
    
    <item>
      <title>Book review of &#34;Nonparametric econometrics&#34; (Pagan and Ullah, 1999)</title>
      <link>https://robjhyndman.com/publications/pagan-and-ullah-nonparametric-econometrics/</link>
      <pubDate>Sun, 16 Jul 2000 00:40:00 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/pagan-and-ullah-nonparametric-econometrics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Smoothing non-Gaussian time series with autoregressive structure</title>
      <link>https://robjhyndman.com/publications/smoothing-non-gaussian-time-series-with-autoregressive-structure/</link>
      <pubDate>Thu, 16 Jul 1998 03:00:13 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/smoothing-non-gaussian-time-series-with-autoregressive-structure/</guid>
      <description>We consider nonparametric smoothing for time series which are clearly non-Gaussian and which are subject to an autoregressive random component. This generalizes methods for smoothing Gaussian series with autoregressive errors, but in the non-Gaussian case the autoregressive structure is not always additive. The problem can be formulated in a general way to include many common non-Gaussian autoregressive models. The amount of smoothing can be chosen by penalized likelihood methods, and we give simulations and parametric bootstrap methods for studying and empirically estimating the penalty function.</description>
    </item>
    
    <item>
      <title>Book Review of &#34;Smoothing methods in Statistics&#34; (Simonoff, 1996)</title>
      <link>https://robjhyndman.com/publications/simonoff-smoothing-methods-in-statistics/</link>
      <pubDate>Wed, 15 Jul 1998 08:36:15 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/simonoff-smoothing-methods-in-statistics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nonparametric autocovariance function estimation</title>
      <link>https://robjhyndman.com/publications/nonparametric-autocovariance-function-estimation/</link>
      <pubDate>Tue, 16 Dec 1997 02:50:35 +0000</pubDate>
      
      <guid>https://robjhyndman.com/publications/nonparametric-autocovariance-function-estimation/</guid>
      <description>Nonparametric estimators of autocovariance functions for non-stationary time series are developed. The estimators are based on straightforward nonparametric mean function estimation ideas and allow use of any linear smoother (e.g. smoothing spline, local polynomial). We study the properties of the estimators and illustrate their usefulness through application to some meteorological and seismic time series.
Keywords: bandwidth; correlated errors; kernel smoothing; local polynomial; nonparametric regression; non-stationary model; time series.
Data: Melbourne maximum temperatures, Kobe earthquake seismograph</description>
    </item>
    
  </channel>
</rss>